{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6512181a-24cf-4abd-a649-e6d413f7aade",
   "metadata": {},
   "source": [
    "# Chapter 7 Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46a4f5-d3a1-4fe8-b92c-030043ef54ad",
   "metadata": {},
   "source": [
    "## 7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64224b57-88fd-4a58-a78d-d8cef1c2f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-06-09, Time: 12:34:56\n",
      "Date: 2025-06-09, Time: 12:35:56\n",
      "Date: 2025-06-09, Time: 12:36:56\n"
     ]
    }
   ],
   "source": [
    "import re  #A\n",
    "\n",
    "# Example log entries  #B\n",
    "logs = [  #C\n",
    "    \"ERROR 2025-06-09 12:34:56 Server failed to respond\",  #D\n",
    "    \"INFO 2025-06-09 12:35:56 User logged in\",  #E\n",
    "    \"WARNING 2025-06-09 12:36:56 Disk space low\"  #F\n",
    "]\n",
    "\n",
    "# Multi-part pattern with capture groups  #G\n",
    "pattern = r\"(\\d{4}-\\d{2}-\\d{2}) (\\d{2}:\\d{2}:\\d{2})\"  #H\n",
    "\n",
    "# Extract date and time from each log entry  #I\n",
    "for log in logs:  #J\n",
    "    match = re.search(pattern, log)  #K\n",
    "    if match:  #L\n",
    "        date, time = match.groups()  #M\n",
    "        print(f\"Date: {date}, Time: {time}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49342500-35df-4400-b63e-fdd29617e4f7",
   "metadata": {},
   "source": [
    "## 7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f87198-5d85-413b-a9af-daa3c7d1bd20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date': '2025-06-09', 'time': '12:34:56'}\n",
      "{'date': '2025-06-09', 'time': '12:35:56'}\n",
      "{'date': '2025-06-09', 'time': '12:36:56'}\n"
     ]
    }
   ],
   "source": [
    "import openai  #A\n",
    "import os  #B\n",
    "from dotenv import load_dotenv  #C\n",
    "from pydantic import BaseModel  #D\n",
    "from typing import Optional  #E\n",
    "\n",
    "# Load API key from .env file  #F\n",
    "load_dotenv()  #G\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  #H\n",
    "\n",
    "# Define the data model for extracted output  #I\n",
    "class LogExtraction(BaseModel):  #J\n",
    "    date: Optional[str]  #K\n",
    "    time: Optional[str]  #L\n",
    "\n",
    "# Example log entries  #M\n",
    "logs = [  #N\n",
    "    \"ERROR 2025-06-09 12:34:56 Server failed to respond\",  #O\n",
    "    \"INFO 2025-06-09 12:35:56 User logged in\",  #P\n",
    "    \"WARNING 2025-06-09 12:36:56 Disk space low\"  #Q\n",
    "]\n",
    "\n",
    "# Prompt for AI to extract date and time  #R\n",
    "row_prompts = [  #S\n",
    "    \"You are a data extraction assistant. Extract the date and time from the log entry:\\n\"\n",
    "    \"- date: Extract the date in YYYY-MM-DD format\\n\"\n",
    "    \"- time: Extract the time in HH:MM:SS format\\n\"\n",
    "    \"Return the result as a JSON object matching the LogExtraction structure.\"\n",
    "    for log in logs  #T\n",
    "]\n",
    "\n",
    "# Process each log entry  #U\n",
    "for log, prompt in zip(logs, row_prompts):  #V\n",
    "    try:  #W\n",
    "        # Make the API call  #X\n",
    "        completion = openai.beta.chat.completions.parse(  #Y\n",
    "            model=\"gpt-4o\",  #Z\n",
    "            messages=[  #AA\n",
    "                {\"role\": \"system\", \"content\": prompt},  #AB\n",
    "                {\"role\": \"user\", \"content\": log}  #AC\n",
    "            ],  #AD\n",
    "            response_format=LogExtraction  #AE\n",
    "        )\n",
    "\n",
    "        extracted = completion.choices[0].message.parsed.dict()  #AF\n",
    "        print(extracted)  #AG\n",
    "\n",
    "    except Exception as e:  #AH\n",
    "        print(f\"Error processing log entry: {e}\")  #AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579247b-d2d1-4f89-a325-1f0e49622564",
   "metadata": {},
   "source": [
    "## 7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "562e9b87-f291-4c5d-8457-a1a25222799a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Library Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Published Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City Library</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>Python Programming</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>Programming, Technology</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Library</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>Data Science 101</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>Data Science, AI</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Library Name  Location               Title      Author  \\\n",
       "0  City Library  Downtown  Python Programming    John Doe   \n",
       "1  City Library  Downtown    Data Science 101  Jane Smith   \n",
       "\n",
       "                    Genres  Published Year  \n",
       "0  Programming, Technology            2020  \n",
       "1         Data Science, AI            2019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd  #A\n",
    "\n",
    "# Function to convert nested JSON to a DataFrame  #B\n",
    "def json_to_dataframe(json_data):  #C\n",
    "    \"\"\"Convert nested JSON to a pandas DataFrame.\"\"\"  #D\n",
    "    records = []  #E\n",
    "    for book in json_data['library']['books']:  #F\n",
    "        record = {  #G\n",
    "            'Library Name': json_data['library']['name'],  #H\n",
    "            'Location': json_data['library']['location'],  #I\n",
    "            'Title': book['title'],  #J\n",
    "            'Author': f\"{book['author']['first_name']} {book['author']['last_name']}\",  #K\n",
    "            'Genres': ', '.join(book['genres']),  #L\n",
    "            'Published Year': book['published_year']  #M\n",
    "        }\n",
    "        records.append(record)  #N\n",
    "    return pd.DataFrame(records)  #O\n",
    "\n",
    "df = json_to_dataframe(json_data) #P\n",
    "display(df) #Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281d10f-0f24-4b33-bd62-6a203fe09f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
