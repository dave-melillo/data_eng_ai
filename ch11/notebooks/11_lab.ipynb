{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Chapter 11 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Environment variables loaded\n",
      "Ready to run lab exercises\n"
     ]
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\u2713 Environment variables loaded\")\n",
    "print(\"Ready to run lab exercises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1",
   "metadata": {},
   "source": [
    "### Question 1: Load curated products\\n\\nLoad the curated backpack list that has been pre-tested for reliable extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davemelillo/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUESTION 1: Load Curated Products\n",
      "============================================================\n",
      "\n",
      "Loaded 10 products from 3 brands\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GORUCK</td>\n",
       "      <td>GR1 26L</td>\n",
       "      <td>Primary example - manufacturer site works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GORUCK</td>\n",
       "      <td>GR2 34L</td>\n",
       "      <td>Larger version of GR1 - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GORUCK</td>\n",
       "      <td>GR3 45L</td>\n",
       "      <td>Travel backpack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GORUCK</td>\n",
       "      <td>Rucker 4.0 20L</td>\n",
       "      <td>Rucking-focused backpack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.11 Tactical</td>\n",
       "      <td>Rush72 2.0</td>\n",
       "      <td>55L tactical backpack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.11 Tactical</td>\n",
       "      <td>Rush24 2.0</td>\n",
       "      <td>37L tactical backpack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.11 Tactical</td>\n",
       "      <td>Rush12 2.0</td>\n",
       "      <td>24L tactical backpack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GORUCK</td>\n",
       "      <td>Bullet Ruck 15L</td>\n",
       "      <td>Compact daypack - works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.11 Tactical</td>\n",
       "      <td>All Hazards Prime</td>\n",
       "      <td>Tactical pack - works via search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Leatherman</td>\n",
       "      <td>Wave+</td>\n",
       "      <td>Multi-tool (bonus test) - works great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name       Product Name  \\\n",
       "0         GORUCK            GR1 26L   \n",
       "1         GORUCK            GR2 34L   \n",
       "2         GORUCK            GR3 45L   \n",
       "3         GORUCK     Rucker 4.0 20L   \n",
       "4  5.11 Tactical         Rush72 2.0   \n",
       "5  5.11 Tactical         Rush24 2.0   \n",
       "6  5.11 Tactical         Rush12 2.0   \n",
       "7         GORUCK    Bullet Ruck 15L   \n",
       "8  5.11 Tactical  All Hazards Prime   \n",
       "9     Leatherman              Wave+   \n",
       "\n",
       "                                             Notes  \n",
       "0  Primary example - manufacturer site works great  \n",
       "1              Larger version of GR1 - works great  \n",
       "2                    Travel backpack - works great  \n",
       "3           Rucking-focused backpack - works great  \n",
       "4              55L tactical backpack - works great  \n",
       "5              37L tactical backpack - works great  \n",
       "6              24L tactical backpack - works great  \n",
       "7                    Compact daypack - works great  \n",
       "8                 Tactical pack - works via search  \n",
       "9            Multi-tool (bonus test) - works great  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2713 Product selection complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 1: Load Curated Products\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the curated backpack list (pre-tested for reliable extraction)\n",
    "df = pd.read_csv(\"../data/curated_backpacks.csv\")\n",
    "\n",
    "print(f\"\\nLoaded {len(df)} products from {df['Brand Name'].nunique()} brands\\n\")\n",
    "display(df)\n",
    "print(f\"\\n\u2713 Product selection complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2",
   "metadata": {},
   "source": [
    "### Question 2: URL Discovery\n",
    "\n",
    "Use SerpAPI to search for product URLs (Listing 11.1) and AI ranking (Listing 11.2) to select the best URL for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "import os\nimport time\nimport requests\nimport openai\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nfrom pydantic import BaseModel\n\nprint(\"=\"*60)\nprint(\"QUESTION 2: URL Discovery & Ranking\")\nprint(\"=\"*60)\n\n# --- Listing 11.1: Search Product URLs ---\nSERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n\ndef search_product_urls(search_key: str, num_results: int = 5) -> list[dict]:\n    \"\"\"Search for product page candidates using SerpAPI.\"\"\"\n    params = {\n        \"q\": search_key,\n        \"api_key\": SERPAPI_KEY,\n        \"num\": num_results,\n        \"engine\": \"google\",\n    }\n    resp = requests.get(\"https://serpapi.com/search\", params=params)\n    resp.raise_for_status()\n    data = resp.json()\n    \n    candidates = []\n    for result in data.get(\"organic_results\", []):\n        candidates.append({\n            \"title\": result.get(\"title\", \"\"),\n            \"url\": result.get(\"link\", \"\"),\n            \"snippet\": result.get(\"snippet\", \"\"),\n            \"position\": result.get(\"position\", 0),\n        })\n    return candidates\n\n# --- Listing 11.2: Rank URLs with AI ---\nclass URLRanking(BaseModel):\n    best_url: str\n    confidence: str\n    reasoning: str\n\ndef rank_urls_with_ai(search_key: str, candidates: list[dict], model: str = \"gpt-4o-mini\") -> URLRanking:\n    \"\"\"Use an LLM to pick the best product page from search results.\"\"\"\n    candidate_text = \"\"\n    for c in candidates:\n        candidate_text += (\n            f\"Position {c['position']}:\n\"\n            f\"  Title: {c['title']}\n\"\n            f\"  URL: {c['url']}\n\"\n            f\"  Snippet: {c['snippet']}\n\n\"\n        )\n    \n    system_prompt = \"\"\"You are a data engineering assistant helping build a product database.\nGiven a product search key and a list of candidate URLs from search results,\npick the single best URL for extracting structured product data.\n\nPrefer:\n1. Manufacturer or official brand pages\n2. Major retailer pages (REI, Backcountry, Moosejaw) if manufacturer unavailable\n3. Pages likely to contain: product name, price, description, weight, images\n4. Individual product pages over category or listing pages\n\nAvoid:\n- Review sites, forums, Reddit threads\n- Category pages that list multiple products\n\nReturn the best URL, your confidence level, and a brief explanation.\"\"\"\n    \n    user_prompt = f\"Product: {search_key}\n\nCandidate URLs:\n{candidate_text}\"\n    \n    response = openai.beta.chat.completions.parse(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n        response_format=URLRanking,\n    )\n    return response.choices[0].message.parsed\n\n# --- Process each product ---\nprint(f\"\nDiscovering URLs for {len(df)} products...\n\")\n\nurl_data = []\nfor _, row in df.iterrows():\n    search_key = f\"{row['Brand Name']} {row['Product Name']}\"\n    print(f\"  \u2022 {search_key}...\")\n    \n    try:\n        # Step 1: Search for URLs\n        candidates = search_product_urls(search_key)\n        \n        # Step 2: Rank URLs with AI\n        if candidates:\n            ranking = rank_urls_with_ai(search_key, candidates)\n            url_data.append({\n                \"brand_name\": row['Brand Name'],\n                \"product_name\": row['Product Name'],\n                \"search_key\": search_key,\n                \"url\": ranking.best_url,\n                \"confidence\": ranking.confidence,\n                \"reasoning\": ranking.reasoning,\n                \"status\": \"success\"\n            })\n            print(f\"    \u2713 {ranking.confidence} confidence\")\n        else:\n            url_data.append({\n                \"brand_name\": row['Brand Name'],\n                \"product_name\": row['Product Name'],\n                \"search_key\": search_key,\n                \"url\": None,\n                \"confidence\": None,\n                \"reasoning\": None,\n                \"status\": \"no_results\"\n            })\n            print(f\"    \u2717 No results\")\n            \n    except Exception as e:\n        print(f\"    \u2717 Error: {type(e).__name__}\")\n        url_data.append({\n            \"brand_name\": row['Brand Name'],\n            \"product_name\": row['Product Name'],\n            \"search_key\": search_key,\n            \"url\": None,\n            \"confidence\": None,\n            \"reasoning\": None,\n            \"status\": f\"error: {type(e).__name__}\"\n        })\n    \n    time.sleep(1)  # Rate limiting\n\n# Create results DataFrame\ndf_urls = pd.DataFrame(url_data)\n\nprint(f\"\nURL Discovery Results:\n\")\ndisplay(df_urls[[\"product_name\", \"brand_name\", \"status\", \"confidence\"]].head(10))\n\nsuccess_count = (df_urls['status'] == 'success').sum()\nprint(f\"\n\u2713 {success_count}/{len(df_urls)} URLs discovered successfully\")"
  },
  {
   "cell_type": "markdown",
   "id": "q3",
   "metadata": {},
   "source": [
    "### Question 3: HTML Cleaning & AI Extraction\n",
    "\n",
    "Fetch HTML, apply aggressive cleaning (Listing 11.3), and extract product data with AI (Listing 11.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3",
   "metadata": {},
   "outputs": [],
   "source": "import time\nimport requests\nimport openai\nfrom bs4 import BeautifulSoup\nfrom pydantic import BaseModel, Field\nfrom typing import Optional\n\nprint(\"=\"*60)\nprint(\"QUESTION 3: HTML Cleaning & AI Extraction\")\nprint(\"=\"*60)\n\n# --- Listing 11.3: Aggressive HTML cleaning ---\nREMOVE_TAGS = [\"script\", \"style\", \"nav\", \"footer\", \"header\", \"iframe\", \"noscript\", \"svg\", \"form\"]\nREMOVE_CLASSES = [\"breadcrumb\", \"related-products\", \"recently-viewed\", \"newsletter\", \"cookie-banner\", \"site-footer\", \"site-header\", \"cart-drawer\", \"search-modal\", \"review\", \"reviews\", \"ratings\"]\n\ndef clean_html_aggressive(html: str) -> str:\n    \"\"\"Remove non-product HTML elements to reduce noise and token count.\"\"\"\n    soup = BeautifulSoup(html, \"html.parser\")\n    \n    for tag_name in REMOVE_TAGS:\n        for element in soup.find_all(tag_name):\n            element.decompose()\n    \n    for class_pattern in REMOVE_CLASSES:\n        for element in soup.find_all(class_=lambda c: c and class_pattern in \" \".join(c).lower()):\n            element.decompose()\n    \n    for element in soup.find_all():\n        if not element.get_text(strip=True) and not element.find(\"img\"):\n            element.decompose()\n    \n    return \" \".join(soup.stripped_strings)\n\n# --- Listing 11.5 & 11.6: Schema and extraction ---\nclass ProductExtraction(BaseModel):\n    product_name: str = Field(description=\"Full product name\")\n    brand_name: str = Field(description=\"Manufacturer or brand\")\n    description: Optional[str] = Field(default=None, description=\"Product description\")\n    price: Optional[str] = Field(default=None, description=\"Current retail price\")\n    weight: Optional[str] = Field(default=None, description=\"Product weight with unit\")\n    primary_image_url: Optional[str] = Field(default=None, description=\"Main image URL\")\n    category: Optional[str] = Field(default=None, description=\"Product category\")\n\nEXTRACTION_PROMPT = \"\"\"You are a product data extraction assistant for a data engineering pipeline.\n\nGiven the text content of a product web page, extract the following fields accurately:\n- product_name: The full product name as displayed on the page\n- brand_name: The manufacturer or brand\n- description: A concise product description (1-3 sentences)\n- price: The current retail price with currency symbol\n- weight: The product weight with unit if available\n- primary_image_url: The URL of the main product image if found in the text\n- category: The product category (backpack, tent, sleeping bag, headlamp, etc.)\n\nRules:\n- Only extract information that is explicitly present in the text\n- Use null for any field you cannot find or confidently determine\n- Do not guess or fabricate values\n- For price, use the current or sale price, not the original price if both are shown\n- For weight, include the unit (lbs, oz, kg, g)\n- For category, use a simple label based on what the product is\"\"\"\n\ndef extract_product_with_ai(cleaned_text: str, model: str = \"gpt-4o-mini\") -> ProductExtraction:\n    \"\"\"Extract product fields from cleaned page text using an LLM.\"\"\"\n    response = openai.beta.chat.completions.parse(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": EXTRACTION_PROMPT},\n            {\"role\": \"user\", \"content\": cleaned_text[:8000]},\n        ],\n        response_format=ProductExtraction,\n    )\n    return response.choices[0].message.parsed\n\n# --- Process successful URL discoveries ---\nprint(f\"\nProcessing {len(df_urls[df_urls['status'] == 'success'])} products...\n\")\n\nextraction_results = []\nfor _, row in df_urls[df_urls['status'] == 'success'].iterrows():\n    record = {\n        \"brand_name\": row['brand_name'],\n        \"product_name\": row['product_name'],\n        \"url\": row['url'],\n        \"status\": \"error\"\n    }\n    \n    try:\n        print(f\"  \u2022 {row['product_name']}...\")\n        \n        # Fetch & clean HTML\n        raw_html = requests.get(row['url'], timeout=10, headers={\"User-Agent\": \"Mozilla/5.0\"}).text\n        cleaned = clean_html_aggressive(raw_html)\n        \n        # Extract with AI\n        extraction = extract_product_with_ai(cleaned)\n        \n        record.update({\n            \"extracted_name\": extraction.product_name,\n            \"extracted_brand\": extraction.brand_name,\n            \"extracted_price\": extraction.price,\n            \"extracted_weight\": extraction.weight,\n            \"extracted_category\": extraction.category,\n            \"raw_chars\": len(raw_html),\n            \"cleaned_chars\": len(cleaned),\n            \"status\": \"success\"\n        })\n        print(f\"    \u2713 Extracted: {extraction.price or 'no price'}\")\n        \n    except Exception as e:\n        print(f\"    \u2717 Error: {type(e).__name__}\")\n        record[\"status\"] = f\"error: {type(e).__name__}\"\n    \n    extraction_results.append(record)\n    time.sleep(2)  # Rate limiting\n\n# Create results DataFrame\nresults_df = pd.DataFrame(extraction_results)\n\nprint(f\"\nExtraction Results:\n\")\ndisplay(results_df[['product_name', 'status', 'extracted_price', 'extracted_weight', 'extracted_category']])\n\nsuccess_count = (results_df['status'] == 'success').sum()\nprint(f\"\n\u2713 {success_count}/{len(results_df)} extractions successful\")"
  },
  {
   "cell_type": "markdown",
   "id": "q4",
   "metadata": {},
   "source": [
    "### Question 4: Evaluate Results\n",
    "\n",
    "Analyze extraction success rate and field coverage across all processed products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"QUESTION 4: Evaluate Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(results_df) > 0:\n",
    "    success_df = results_df[results_df['status'] == 'success']\n",
    "    total = len(results_df)\n",
    "    success_count = len(success_df)\n",
    "    \n",
    "    # Summary stats\n",
    "    print(f\"\\nExtraction Summary:\\n\")\n",
    "    summary = pd.DataFrame({\n",
    "        \"Metric\": [\"Total products\", \"Successful\", \"Failed\", \"Success rate\"],\n",
    "        \"Value\": [\n",
    "            total,\n",
    "            success_count,\n",
    "            total - success_count,\n",
    "            f\"{success_count / total:.0%}\" if total > 0 else \"N/A\"\n",
    "        ]\n",
    "    })\n",
    "    display(summary)\n",
    "    \n",
    "    # Field coverage\n",
    "    if success_count > 0:\n",
    "        fields = ['extracted_name', 'extracted_brand', 'extracted_price', 'extracted_weight', 'extracted_category']\n",
    "        coverage_data = []\n",
    "        for field in fields:\n",
    "            if field in success_df.columns:\n",
    "                populated = success_df[field].notna().sum()\n",
    "                coverage_data.append({\n",
    "                    \"Field\": field.replace('extracted_', ''),\n",
    "                    \"Populated\": populated,\n",
    "                    \"Coverage\": f\"{populated}/{success_count}\",\n",
    "                    \"Percentage\": f\"{populated/success_count:.0%}\"\n",
    "                })\n",
    "        \n",
    "        coverage_df = pd.DataFrame(coverage_data)\n",
    "        print(f\"\\nField Coverage (of successful extractions):\\n\")\n",
    "        display(coverage_df)\n",
    "        \n",
    "        avg_coverage = coverage_df['Populated'].sum() / (len(coverage_df) * success_count) * 100\n",
    "        print(f\"\\n\u2713 Average field coverage: {avg_coverage:.0f}%\")\n",
    "    else:\n",
    "        print(\"\\nNo successful extractions to evaluate\")\n",
    "else:\n",
    "    print(\"\\nNo data to evaluate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}