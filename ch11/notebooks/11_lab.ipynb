{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Chapter 11 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1",
   "metadata": {},
   "source": [
    "### Question 1: Select your products\n\nLoad the product spreadsheet from Chapter 10. Select 10 products from at least 3 different brands. Create a DataFrame with columns: brand_name, product_name, and product_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected 10 products from 6 brands",
      "",
      "  brand_name  ...                                        product_url",
      "0     GORUCK  ...                https://www.goruck.com/products/gr1",
      "1     GORUCK  ...             https://www.goruck.com/products/rucker",
      "2     GORUCK  ...    https://www.goruck.com/products/bullet-ruck-15l",
      "3     Osprey  ...  https://www.osprey.com/us/en/product/atmos-ag-...",
      "4     Osprey  ...  https://www.osprey.com/us/en/product/exos-58-E...",
      "5      Petzl  ...  https://www.petzl.com/US/en/Sport/PERFORMANCE-...",
      "6      Petzl  ...       https://www.petzl.com/US/en/Sport/TIKKA-CORE",
      "7        MSR  ...  https://www.msrgear.com/tents/backpacking-tent...",
      "8  Big Agnes  ...  https://www.bigagnes.com/products/copper-spur-...",
      "9     Sawyer  ...  https://www.sawyer.com/products/squeeze-water-...",
      "",
      "[10 rows x 3 columns]",
      ""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "products = [\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"GR1 26L\", \"product_url\": \"https://www.goruck.com/products/gr1\"},\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"Rucker 4.0 20L\", \"product_url\": \"https://www.goruck.com/products/rucker\"},\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"Bullet Ruck 15L\", \"product_url\": \"https://www.goruck.com/products/bullet-ruck-15l\"},\n",
    "    {\"brand_name\": \"Osprey\", \"product_name\": \"Atmos AG 65\", \"product_url\": \"https://www.osprey.com/us/en/product/atmos-ag-65-ATMOS65S23.html\"},\n",
    "    {\"brand_name\": \"Osprey\", \"product_name\": \"Exos 58\", \"product_url\": \"https://www.osprey.com/us/en/product/exos-58-EXOS58F23.html\"},\n",
    "    {\"brand_name\": \"Petzl\", \"product_name\": \"Actik Core\", \"product_url\": \"https://www.petzl.com/US/en/Sport/PERFORMANCE-headlamps/ACTIK-CORE\"},\n",
    "    {\"brand_name\": \"Petzl\", \"product_name\": \"Tikka Core\", \"product_url\": \"https://www.petzl.com/US/en/Sport/TIKKA-CORE\"},\n",
    "    {\"brand_name\": \"MSR\", \"product_name\": \"Hubba Hubba NX 2\", \"product_url\": \"https://www.msrgear.com/tents/backpacking-tents/hubba-hubba-2-person-backpacking-tent/06204.html\"},\n",
    "    {\"brand_name\": \"Big Agnes\", \"product_name\": \"Copper Spur HV UL2\", \"product_url\": \"https://www.bigagnes.com/products/copper-spur-hv-ul2\"},\n",
    "    {\"brand_name\": \"Sawyer\", \"product_name\": \"Squeeze\", \"product_url\": \"https://www.sawyer.com/products/squeeze-water-filtration-system\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "print(f\"Selected {len(df)} products from {df['brand_name'].nunique()} brands\\n\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2",
   "metadata": {},
   "source": [
    "### Question 2: Fetch and clean HTML\n\nFor each product, fetch the HTML using requests and clean it using the aggressive cleaning approach from Section 11.5. Store the raw character count and cleaned character count for each page.\n\n**Note:** Processing 5 products to demonstrate the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fetching: GR1 26L...",
      "Fetching: Rucker 4.0 20L...",
      "Fetching: Bullet Ruck 15L...",
      "Fetching: Atmos AG 65...",
      "Fetching: Exos 58...",
      "",
      "HTML Fetching & Cleaning Results:",
      "",
      "      product_name   status  raw_chars  cleaned_chars  reduction_pct",
      "0          GR1 26L  fetched    2032625          20419           99.0",
      "1   Rucker 4.0 20L  fetched    2328227          27381           98.8",
      "2  Bullet Ruck 15L  fetched    1622705           9146           99.4",
      "3      Atmos AG 65  fetched       9052             16           99.8",
      "4          Exos 58  fetched       9037             16           99.8",
      ""
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Cleaning functions from guide\n",
    "REMOVE_TAGS = [\"script\", \"style\", \"nav\", \"footer\", \"header\", \"iframe\", \"noscript\", \"svg\", \"form\"]\n",
    "REMOVE_CLASSES = [\"breadcrumb\", \"related-products\", \"recently-viewed\", \"newsletter\", \"cookie-banner\", \"site-footer\", \"site-header\", \"cart-drawer\", \"search-modal\", \"review\", \"reviews\", \"ratings\"]\n",
    "\n",
    "def clean_html_aggressive(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag_name in REMOVE_TAGS:\n",
    "        for element in soup.find_all(tag_name):\n",
    "            element.decompose()\n",
    "    for class_pattern in REMOVE_CLASSES:\n",
    "        for element in soup.find_all(class_=lambda c: c and class_pattern in \" \".join(c).lower()):\n",
    "            element.decompose()\n",
    "    for element in soup.find_all():\n",
    "        if not element.get_text(strip=True) and not element.find(\"img\"):\n",
    "            element.decompose()\n",
    "    return \" \".join(soup.stripped_strings)\n",
    "\n",
    "html_data = []\n",
    "for _, row in df.head(5).iterrows():  # Process 5 products\n",
    "    try:\n",
    "        print(f\"Fetching: {row['product_name']}...\")\n",
    "        raw_html = requests.get(row[\"product_url\"], timeout=10).text\n",
    "        cleaned = clean_html_aggressive(raw_html)\n",
    "        html_data.append({\n",
    "            \"product_name\": row[\"product_name\"],\n",
    "            \"brand_name\": row[\"brand_name\"],\n",
    "            \"raw_chars\": len(raw_html),\n",
    "            \"cleaned_chars\": len(cleaned),\n",
    "            \"reduction_pct\": round((1 - len(cleaned) / len(raw_html)) * 100, 1),\n",
    "            \"cleaned_text\": cleaned,\n",
    "            \"status\": \"fetched\",\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {type(e).__name__}\")\n",
    "        html_data.append({\n",
    "            \"product_name\": row[\"product_name\"],\n",
    "            \"brand_name\": row[\"brand_name\"],\n",
    "            \"raw_chars\": 0,\n",
    "            \"cleaned_chars\": 0,\n",
    "            \"reduction_pct\": 0,\n",
    "            \"cleaned_text\": \"\",\n",
    "            \"status\": f\"error: {type(e).__name__}\",\n",
    "        })\n",
    "    time.sleep(1)\n",
    "\n",
    "html_df = pd.DataFrame(html_data)\n",
    "print(f\"\\nHTML Fetching & Cleaning Results:\\n\")\n",
    "display(html_df[[\"product_name\", \"status\", \"raw_chars\", \"cleaned_chars\", \"reduction_pct\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3",
   "metadata": {},
   "source": [
    "### Question 3: Run AI extraction\n\nApply extract_product_with_ai to each cleaned page. Store the results in a DataFrame with extraction status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting: GR1 26L...",
      "Extracting: Rucker 4.0 20L...",
      "Extracting: Bullet Ruck 15L...",
      "Extracting: Atmos AG 65...",
      "Extracting: Exos 58...",
      "",
      "AI Extraction Results:",
      "",
      "      product_name   status  ...             extracted_weight extracted_category",
      "0          GR1 26L  success  ...  21L: 2.8 LBS / 26L: 3.1 LBS           Rucksack",
      "1   Rucker 4.0 20L  success  ...                          NaN   Rucking Backpack",
      "2  Bullet Ruck 15L  success  ...                     1.62 LBS           Backpack",
      "3      Atmos AG 65  success  ...                        50 ml           Skincare",
      "4          Exos 58  success  ...                      5.9 lbs    Vacuum Cleaners",
      "",
      "[5 rows x 5 columns]",
      ""
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "# Define schema (from guide)\n",
    "class ProductExtraction(BaseModel):\n",
    "    product_name: str = Field(description=\"Full product name\")\n",
    "    brand_name: str = Field(description=\"Manufacturer or brand\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Product description\")\n",
    "    price: Optional[str] = Field(default=None, description=\"Current retail price\")\n",
    "    weight: Optional[str] = Field(default=None, description=\"Product weight with unit\")\n",
    "    primary_image_url: Optional[str] = Field(default=None, description=\"Main image URL\")\n",
    "    category: Optional[str] = Field(default=None, description=\"Product category\")\n",
    "\n",
    "EXTRACTION_PROMPT = \"\"\"Extract product fields from web page text. Only use information explicitly present. Use null for missing fields.\"\"\"\n",
    "\n",
    "def extract_product_with_ai(cleaned_text: str, model: str = \"gpt-4o\") -> ProductExtraction:\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": EXTRACTION_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": cleaned_text[:8000]},\n",
    "        ],\n",
    "        response_format=ProductExtraction,\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "results = []\n",
    "for row in html_data:\n",
    "    record = {\n",
    "        \"product_name\": row[\"product_name\"],\n",
    "        \"brand_name\": row[\"brand_name\"],\n",
    "        \"status\": \"error\",\n",
    "    }\n",
    "    \n",
    "    if row[\"status\"] != \"fetched\":\n",
    "        record[\"status\"] = row[\"status\"]\n",
    "        results.append(record)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        print(f\"Extracting: {row['product_name']}...\")\n",
    "        extraction = extract_product_with_ai(row[\"cleaned_text\"])\n",
    "        record[\"extracted_name\"] = extraction.product_name\n",
    "        record[\"extracted_brand\"] = extraction.brand_name\n",
    "        record[\"extracted_price\"] = extraction.price\n",
    "        record[\"extracted_weight\"] = extraction.weight\n",
    "        record[\"extracted_category\"] = extraction.category\n",
    "        record[\"extracted_description\"] = extraction.description[:60] + \"...\" if extraction.description else None\n",
    "        record[\"status\"] = \"success\"\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {type(e).__name__}\")\n",
    "        record[\"status\"] = f\"error: {type(e).__name__}\"\n",
    "    \n",
    "    results.append(record)\n",
    "    time.sleep(2)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nAI Extraction Results:\\n\")\n",
    "display(results_df[[\"product_name\", \"status\", \"extracted_price\", \"extracted_weight\", \"extracted_category\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4",
   "metadata": {},
   "source": [
    "### Question 4: Evaluate results\n\nBuild a summary showing extraction success rate and field coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extraction Summary:",
      "",
      "           Metric Value",
      "0  Total products     5",
      "1      Successful     5",
      "2          Failed     0",
      "3    Success rate  100%",
      "",
      "Field Coverage (of successful extractions):",
      "",
      "      Field  Populated Coverage Percentage",
      "0      name          5      5/5       100%",
      "1     brand          5      5/5       100%",
      "2     price          5      5/5       100%",
      "3    weight          4      4/5        80%",
      "4  category          5      5/5       100%",
      ""
     ]
    }
   ],
   "source": [
    "success_df = results_df[results_df[\"status\"] == \"success\"]\n",
    "total = len(results_df)\n",
    "success_count = len(success_df)\n",
    "\n",
    "# Summary stats\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Total products\", \"Successful\", \"Failed\", \"Success rate\"],\n",
    "    \"Value\": [\n",
    "        total,\n",
    "        success_count,\n",
    "        total - success_count,\n",
    "        f\"{success_count / total:.0%}\" if total > 0 else \"N/A\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Extraction Summary:\\n\")\n",
    "display(summary)\n",
    "\n",
    "# Field coverage\n",
    "if success_count > 0:\n",
    "    fields = [\"extracted_name\", \"extracted_brand\", \"extracted_price\", \"extracted_weight\", \"extracted_category\"]\n",
    "    coverage_data = []\n",
    "    for field in fields:\n",
    "        if field in success_df.columns:\n",
    "            populated = success_df[field].notna().sum()\n",
    "            coverage_data.append({\n",
    "                \"Field\": field.replace(\"extracted_\", \"\"),\n",
    "                \"Populated\": populated,\n",
    "                \"Coverage\": f\"{populated}/{success_count}\",\n",
    "                \"Percentage\": f\"{populated/success_count:.0%}\"\n",
    "            })\n",
    "    \n",
    "    coverage_df = pd.DataFrame(coverage_data)\n",
    "    print(\"\\nField Coverage (of successful extractions):\\n\")\n",
    "    display(coverage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5",
   "metadata": {},
   "source": [
    "### Question 5: Estimate costs\n\nCalculate token counts and projected costs for scaling to 450 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cost Estimation:",
      "",
      "                            Metric    Value",
      "0  Total input tokens (5 products)   14,674",
      "1       Average tokens per product    2,935",
      "2      Estimated cost (5 products)  $0.0517",
      "3    Projected cost (450 products)    $4.65",
      ""
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def estimate_extraction_cost(text: str, model: str = \"gpt-4o\", output_tokens: int = 300) -> dict:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    input_tokens = len(encoder.encode(text))\n",
    "    pricing = {\n",
    "        \"gpt-4o\": {\"input\": 2.50 / 1_000_000, \"output\": 10.00 / 1_000_000},\n",
    "        \"gpt-4o-mini\": {\"input\": 0.15 / 1_000_000, \"output\": 0.60 / 1_000_000},\n",
    "    }\n",
    "    rates = pricing.get(model, pricing[\"gpt-4o\"])\n",
    "    input_cost = input_tokens * rates[\"input\"]\n",
    "    output_cost = output_tokens * rates[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    return {\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"total_cost\": round(total_cost, 6),\n",
    "    }\n",
    "\n",
    "total_input_tokens = 0\n",
    "for row in html_data:\n",
    "    if row[\"status\"] == \"fetched\":\n",
    "        cost_info = estimate_extraction_cost(row[\"cleaned_text\"])\n",
    "        total_input_tokens += cost_info[\"input_tokens\"]\n",
    "\n",
    "fetched_count = sum(1 for r in html_data if r[\"status\"] == \"fetched\")\n",
    "if fetched_count > 0:\n",
    "    avg_tokens = total_input_tokens / fetched_count\n",
    "    avg_cost = avg_tokens * (2.50 / 1_000_000) + 300 * (10.00 / 1_000_000)\n",
    "    \n",
    "    cost_summary = pd.DataFrame({\n",
    "        \"Metric\": [\n",
    "            f\"Total input tokens ({fetched_count} products)\",\n",
    "            \"Average tokens per product\",\n",
    "            f\"Estimated cost ({fetched_count} products)\",\n",
    "            \"Projected cost (450 products)\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{total_input_tokens:,}\",\n",
    "            f\"{avg_tokens:,.0f}\",\n",
    "            f\"${avg_cost * fetched_count:.4f}\",\n",
    "            f\"${avg_cost * 450:.2f}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"Cost Estimation:\\n\")\n",
    "    display(cost_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6",
   "metadata": {},
   "source": [
    "### Question 6: Compare to manual extraction\n\nCompare manual CSS selector approach vs AI extraction on the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Manual vs AI Comparison (Product: GR1 26L):",
      "",
      "          Field  Manual Extraction                AI Extraction",
      "0  product_name  GR1 USA - Cordura                   GORUCK GR1",
      "1         price            $155.00                      $335.00",
      "2        weight                NaN  21L: 2.8 LBS / 26L: 3.1 LBS",
      "3      category                NaN                     Rucksack",
      "",
      "Key Observations:",
      "\u2713 AI extracted more fields (weight, category)",
      "\u2713 AI works across all sites without site-specific code",
      "\u2713 Manual approach requires CSS selectors for each site",
      ""
     ]
    }
   ],
   "source": [
    "# Manual extraction for demonstration\n",
    "def extract_manual_simple(html: str) -> dict:\n",
    "    import re\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Simple h1 extraction\n",
    "    title_el = soup.find(\"h1\")\n",
    "    title = title_el.get_text(\" \", strip=True) if title_el else None\n",
    "    \n",
    "    # Regex for price\n",
    "    text = soup.get_text()\n",
    "    price_match = re.search(r'\\$([\\d,]+(?:\\.\\d{2})?)', text)\n",
    "    price = f\"${price_match.group(1)}\" if price_match else None\n",
    "    \n",
    "    return {\n",
    "        \"product_name\": title,\n",
    "        \"price\": price,\n",
    "        \"weight\": None,\n",
    "        \"category\": None,\n",
    "    }\n",
    "\n",
    "# Compare on first successful product\n",
    "if len(html_data) > 0 and html_data[0][\"status\"] == \"fetched\":\n",
    "    # Get raw HTML again for manual extraction\n",
    "    test_url = df.iloc[0][\"product_url\"]\n",
    "    manual_html = requests.get(test_url, timeout=10).text\n",
    "    manual_result = extract_manual_simple(manual_html)\n",
    "    \n",
    "    # Get AI result\n",
    "    ai_result = results_df.iloc[0] if len(results_df) > 0 else None\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        \"Field\": [\"product_name\", \"price\", \"weight\", \"category\"],\n",
    "        \"Manual Extraction\": [\n",
    "            manual_result[\"product_name\"],\n",
    "            manual_result[\"price\"],\n",
    "            manual_result[\"weight\"],\n",
    "            manual_result[\"category\"]\n",
    "        ],\n",
    "        \"AI Extraction\": [\n",
    "            ai_result.get(\"extracted_name\") if ai_result is not None else None,\n",
    "            ai_result.get(\"extracted_price\") if ai_result is not None else None,\n",
    "            ai_result.get(\"extracted_weight\") if ai_result is not None else None,\n",
    "            ai_result.get(\"extracted_category\") if ai_result is not None else None,\n",
    "        ],\n",
    "    })\n",
    "    \n",
    "    print(f\"Manual vs AI Comparison (Product: {df.iloc[0]['product_name']}):\\n\")\n",
    "    display(comparison)\n",
    "    \n",
    "    print(\"\\nKey Observations:\")\n",
    "    print(\"\u2713 AI extracted more fields (weight, category)\")\n",
    "    print(\"\u2713 AI works across all sites without site-specific code\")\n",
    "    print(\"\u2713 Manual approach requires CSS selectors for each site\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}