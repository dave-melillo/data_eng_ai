{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Chapter 11 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "traceback": [
      "No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\u2713 Environment variables loaded\")\n",
    "print(\"Ready to run lab exercises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q1",
   "metadata": {},
   "source": [
    "### Question 1: Select your products\n\nCreate a DataFrame with 10 products from at least 3 different brands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================",
      "QUESTION 1: Select Products",
      "============================================================",
      "",
      "Selected 10 products from 6 brands",
      "",
      "  brand_name  ...                                        product_url",
      "0     GORUCK  ...                https://www.goruck.com/products/gr1",
      "1     GORUCK  ...             https://www.goruck.com/products/rucker",
      "2     GORUCK  ...    https://www.goruck.com/products/bullet-ruck-15l",
      "3     Osprey  ...  https://www.osprey.com/us/en/product/atmos-ag-...",
      "4     Osprey  ...  https://www.osprey.com/us/en/product/exos-58-E...",
      "5      Petzl  ...  https://www.petzl.com/US/en/Sport/PERFORMANCE-...",
      "6      Petzl  ...       https://www.petzl.com/US/en/Sport/TIKKA-CORE",
      "7        MSR  ...  https://www.msrgear.com/tents/backpacking-tent...",
      "8  Big Agnes  ...  https://www.bigagnes.com/products/copper-spur-...",
      "9     Sawyer  ...  https://www.sawyer.com/products/squeeze-water-...",
      "",
      "[10 rows x 3 columns]",
      "",
      "\u2713 Product selection complete",
      ""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 1: Select Products\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "products = [\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"GR1 26L\", \"product_url\": \"https://www.goruck.com/products/gr1\"},\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"Rucker 4.0 20L\", \"product_url\": \"https://www.goruck.com/products/rucker\"},\n",
    "    {\"brand_name\": \"GORUCK\", \"product_name\": \"Bullet Ruck 15L\", \"product_url\": \"https://www.goruck.com/products/bullet-ruck-15l\"},\n",
    "    {\"brand_name\": \"Osprey\", \"product_name\": \"Atmos AG 65\", \"product_url\": \"https://www.osprey.com/us/en/product/atmos-ag-65-ATMOS65S23.html\"},\n",
    "    {\"brand_name\": \"Osprey\", \"product_name\": \"Exos 58\", \"product_url\": \"https://www.osprey.com/us/en/product/exos-58-EXOS58F23.html\"},\n",
    "    {\"brand_name\": \"Petzl\", \"product_name\": \"Actik Core\", \"product_url\": \"https://www.petzl.com/US/en/Sport/PERFORMANCE-headlamps/ACTIK-CORE\"},\n",
    "    {\"brand_name\": \"Petzl\", \"product_name\": \"Tikka Core\", \"product_url\": \"https://www.petzl.com/US/en/Sport/TIKKA-CORE\"},\n",
    "    {\"brand_name\": \"MSR\", \"product_name\": \"Hubba Hubba NX 2\", \"product_url\": \"https://www.msrgear.com/tents/backpacking-tents/hubba-hubba-2-person-backpacking-tent/06204.html\"},\n",
    "    {\"brand_name\": \"Big Agnes\", \"product_name\": \"Copper Spur HV UL2\", \"product_url\": \"https://www.bigagnes.com/products/copper-spur-hv-ul2\"},\n",
    "    {\"brand_name\": \"Sawyer\", \"product_name\": \"Squeeze\", \"product_url\": \"https://www.sawyer.com/products/squeeze-water-filtration-system\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "print(f\"\\nSelected {len(df)} products from {df['brand_name'].nunique()} brands\\n\")\n",
    "display(df)\n",
    "print(f\"\\n\u2713 Product selection complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q2",
   "metadata": {},
   "source": [
    "### Question 2: Fetch and clean HTML\n\nFetch HTML for each product and apply aggressive cleaning. Demonstrate with 5 products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================",
      "QUESTION 2: Fetch & Clean HTML",
      "============================================================",
      "",
      "Fetching & cleaning HTML for 5 products...",
      "",
      "  \u2022 GR1 26L...",
      "  \u2022 Rucker 4.0 20L...",
      "  \u2022 Bullet Ruck 15L...",
      "  \u2022 Atmos AG 65...",
      "  \u2022 Exos 58...",
      "",
      "HTML Fetching & Cleaning Results:",
      "",
      "      product_name   status  raw_chars  cleaned_chars  reduction_pct",
      "0          GR1 26L  fetched    2032630          20419           99.0",
      "1   Rucker 4.0 20L  fetched    2328227          27381           98.8",
      "2  Bullet Ruck 15L  fetched    1622606           9146           99.4",
      "3      Atmos AG 65  fetched       9052             16           99.8",
      "4          Exos 58  fetched       8995             16           99.8",
      "",
      "\u2713 Average HTML reduction: 99.4%",
      ""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 2: Fetch & Clean HTML\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cleaning functions from guide\n",
    "REMOVE_TAGS = [\"script\", \"style\", \"nav\", \"footer\", \"header\", \"iframe\", \"noscript\", \"svg\", \"form\"]\n",
    "REMOVE_CLASSES = [\"breadcrumb\", \"related-products\", \"recently-viewed\", \"newsletter\", \"cookie-banner\", \"site-footer\", \"site-header\", \"cart-drawer\", \"search-modal\", \"review\", \"reviews\", \"ratings\"]\n",
    "\n",
    "def clean_html_aggressive(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag_name in REMOVE_TAGS:\n",
    "        for element in soup.find_all(tag_name):\n",
    "            element.decompose()\n",
    "    for class_pattern in REMOVE_CLASSES:\n",
    "        for element in soup.find_all(class_=lambda c: c and class_pattern in \" \".join(c).lower()):\n",
    "            element.decompose()\n",
    "    for element in soup.find_all():\n",
    "        if not element.get_text(strip=True) and not element.find(\"img\"):\n",
    "            element.decompose()\n",
    "    return \" \".join(soup.stripped_strings)\n",
    "\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "\n",
    "def search_fallback_url(brand: str, product: str, avoid_domain: str = None) -> str:\n",
    "    \"\"\"Search for a working product URL when direct fetch fails.\"\"\"\n",
    "    # Search with retailer preference for JS-heavy brand sites\n",
    "    search_key = f\"{brand} {product} buy\"\n",
    "    params = {\"q\": search_key, \"api_key\": SERPAPI_KEY, \"num\": 10, \"engine\": \"google\"}\n",
    "    resp = requests.get(\"https://serpapi.com/search\", params=params)\n",
    "    results = resp.json().get(\"organic_results\", [])\n",
    "    \n",
    "    # Prefer retailers with static HTML (REI, Backcountry, etc.)\n",
    "    preferred_retailers = [\"rei.com\", \"backcountry.com\", \"moosejaw.com\", \"ems.com\"]\n",
    "    \n",
    "    for r in results:\n",
    "        url = r.get(\"link\", \"\")\n",
    "        # Skip the domain that didn't work\n",
    "        if avoid_domain and avoid_domain in url:\n",
    "            continue\n",
    "        # Prefer known good retailers\n",
    "        if any(retailer in url for retailer in preferred_retailers):\n",
    "            return url\n",
    "    \n",
    "    # Fallback: any result not from the avoided domain\n",
    "    for r in results:\n",
    "        url = r.get(\"link\", \"\")\n",
    "        if avoid_domain and avoid_domain not in url:\n",
    "            return url\n",
    "    return None\n",
    "\n",
    "print(f\"\\nFetching & cleaning HTML for 5 products...\\n\")\n",
    "\n",
    "html_data = []\n",
    "for _, row in df.head(5).iterrows():\n",
    "    try:\n",
    "        print(f\"  \u2022 {row['product_name']}...\")\n",
    "        url = row[\"product_url\"]\n",
    "        raw_html = requests.get(url, timeout=10).text\n",
    "        cleaned = clean_html_aggressive(raw_html)\n",
    "        \n",
    "        # Fallback: if cleaned content is too short, search for a better URL\n",
    "        if len(cleaned) < 100:\n",
    "            from urllib.parse import urlparse\n",
    "            original_domain = urlparse(url).netloc\n",
    "            print(f\"    \u2192 Content too short ({len(cleaned)} chars), searching for better URL...\")\n",
    "            print(f\"    \u2192 Avoiding {original_domain} (JS-heavy)\")\n",
    "            fallback_url = search_fallback_url(row[\"brand_name\"], row[\"product_name\"], avoid_domain=original_domain)\n",
    "            if fallback_url and fallback_url != url:\n",
    "                print(f\"    \u2192 Found: {fallback_url[:60]}...\")\n",
    "                raw_html = requests.get(fallback_url, timeout=10).text\n",
    "                cleaned = clean_html_aggressive(raw_html)\n",
    "                url = fallback_url\n",
    "        \n",
    "        html_data.append({\n",
    "            \"product_name\": row[\"product_name\"],\n",
    "            \"brand_name\": row[\"brand_name\"],\n",
    "            \"raw_chars\": len(raw_html),\n",
    "            \"cleaned_chars\": len(cleaned),\n",
    "            \"reduction_pct\": round((1 - len(cleaned) / len(raw_html)) * 100, 1),\n",
    "            \"cleaned_text\": cleaned,\n",
    "            \"status\": \"fetched\",\n",
    "            \"url_used\": url,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {type(e).__name__}\")\n",
    "        html_data.append({\n",
    "            \"product_name\": row[\"product_name\"],\n",
    "            \"brand_name\": row[\"brand_name\"],\n",
    "            \"raw_chars\": 0,\n",
    "            \"cleaned_chars\": 0,\n",
    "            \"reduction_pct\": 0,\n",
    "            \"cleaned_text\": \"\",\n",
    "            \"status\": f\"error: {type(e).__name__}\",\n",
    "            \"url_used\": row[\"product_url\"],\n",
    "        })\n",
    "    time.sleep(1)\n",
    "\n",
    "html_df = pd.DataFrame(html_data)\n",
    "print(f\"\\nHTML Fetching & Cleaning Results:\\n\")\n",
    "display(html_df[[\"product_name\", \"status\", \"raw_chars\", \"cleaned_chars\", \"reduction_pct\"]])\n",
    "\n",
    "avg_reduction = html_df[html_df[\"status\"] == \"fetched\"][\"reduction_pct\"].mean()\n",
    "print(f\"\\n\u2713 Average HTML reduction: {avg_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q3",
   "metadata": {},
   "source": [
    "### Question 3: Run AI extraction\n\nExtract product data using AI for all successfully fetched pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================",
      "QUESTION 3: AI Product Extraction",
      "============================================================",
      "",
      "Running AI extraction on 5 products...",
      "",
      "  \u2022 GR1 26L...",
      "  \u2022 Rucker 4.0 20L...",
      "  \u2022 Bullet Ruck 15L...",
      "  \u2022 Atmos AG 65...",
      "  \u2022 Exos 58...",
      "",
      "AI Extraction Results:",
      "",
      "      product_name   status  ...               extracted_weight extracted_category",
      "0          GR1 26L  success  ...  2.8 LBS (21L) / 3.1 LBS (26L)           Rucksack",
      "1   Rucker 4.0 20L  success  ...                            NaN   Rucking Backpack",
      "2  Bullet Ruck 15L  success  ...                       1.62 LBS          Backpacks",
      "3      Atmos AG 65  success  ...                           169g        Smartphones",
      "4          Exos 58  success  ...                    10.4 ounces        Electronics",
      "",
      "[5 rows x 5 columns]",
      "",
      "\u2713 5/5 extractions successful",
      ""
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 3: AI Product Extraction\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define schema\n",
    "class ProductExtraction(BaseModel):\n",
    "    product_name: str = Field(description=\"Full product name\")\n",
    "    brand_name: str = Field(description=\"Manufacturer or brand\")\n",
    "    description: Optional[str] = Field(default=None, description=\"Product description\")\n",
    "    price: Optional[str] = Field(default=None, description=\"Current retail price\")\n",
    "    weight: Optional[str] = Field(default=None, description=\"Product weight with unit\")\n",
    "    primary_image_url: Optional[str] = Field(default=None, description=\"Main image URL\")\n",
    "    category: Optional[str] = Field(default=None, description=\"Product category\")\n",
    "\n",
    "EXTRACTION_PROMPT = \"\"\"Extract product fields from web page text. Only use information explicitly present. Use null for missing fields.\"\"\"\n",
    "\n",
    "def extract_product_with_ai(cleaned_text: str, model: str = \"gpt-4o\") -> ProductExtraction:\n",
    "    response = openai.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": EXTRACTION_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": cleaned_text[:8000]},\n",
    "        ],\n",
    "        response_format=ProductExtraction,\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "print(f\"\\nRunning AI extraction on {len(html_data)} products...\\n\")\n",
    "\n",
    "results = []\n",
    "for row in html_data:\n",
    "    record = {\n",
    "        \"product_name\": row[\"product_name\"],\n",
    "        \"brand_name\": row[\"brand_name\"],\n",
    "        \"status\": \"error\",\n",
    "    }\n",
    "    \n",
    "    if row[\"status\"] != \"fetched\":\n",
    "        record[\"status\"] = row[\"status\"]\n",
    "        results.append(record)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        print(f\"  \u2022 {row['product_name']}...\")\n",
    "        extraction = extract_product_with_ai(row[\"cleaned_text\"])\n",
    "        record[\"extracted_name\"] = extraction.product_name\n",
    "        record[\"extracted_brand\"] = extraction.brand_name\n",
    "        record[\"extracted_price\"] = extraction.price\n",
    "        record[\"extracted_weight\"] = extraction.weight\n",
    "        record[\"extracted_category\"] = extraction.category\n",
    "        record[\"extracted_description\"] = extraction.description[:60] + \"...\" if extraction.description else None\n",
    "        record[\"status\"] = \"success\"\n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {type(e).__name__}\")\n",
    "        record[\"status\"] = f\"error: {type(e).__name__}\"\n",
    "    \n",
    "    results.append(record)\n",
    "    time.sleep(2)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nAI Extraction Results:\\n\")\n",
    "display(results_df[[\"product_name\", \"status\", \"extracted_price\", \"extracted_weight\", \"extracted_category\"]])\n",
    "\n",
    "success_count = (results_df[\"status\"] == \"success\").sum()\n",
    "print(f\"\\n\u2713 {success_count}/{len(results_df)} extractions successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q4",
   "metadata": {},
   "source": [
    "### Question 4: Evaluate results\n\nAnalyze extraction success rate and field coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================",
      "QUESTION 4: Evaluate Results",
      "============================================================",
      "",
      "Extraction Summary:",
      "",
      "           Metric Value",
      "0  Total products     5",
      "1      Successful     5",
      "2          Failed     0",
      "3    Success rate  100%",
      "",
      "Field Coverage (of successful extractions):",
      "",
      "      Field  Populated Coverage Percentage",
      "0      name          5      5/5       100%",
      "1     brand          5      5/5       100%",
      "2     price          5      5/5       100%",
      "3    weight          4      4/5        80%",
      "4  category          5      5/5       100%",
      "",
      "\u2713 Average field coverage: 96%",
      ""
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"QUESTION 4: Evaluate Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "success_df = results_df[results_df[\"status\"] == \"success\"]\n",
    "total = len(results_df)\n",
    "success_count = len(success_df)\n",
    "\n",
    "# Summary stats\n",
    "print(f\"\\nExtraction Summary:\\n\")\n",
    "summary = pd.DataFrame({\n",
    "    \"Metric\": [\"Total products\", \"Successful\", \"Failed\", \"Success rate\"],\n",
    "    \"Value\": [\n",
    "        total,\n",
    "        success_count,\n",
    "        total - success_count,\n",
    "        f\"{success_count / total:.0%}\" if total > 0 else \"N/A\"\n",
    "    ]\n",
    "})\n",
    "display(summary)\n",
    "\n",
    "# Field coverage\n",
    "if success_count > 0:\n",
    "    fields = [\"extracted_name\", \"extracted_brand\", \"extracted_price\", \"extracted_weight\", \"extracted_category\"]\n",
    "    coverage_data = []\n",
    "    for field in fields:\n",
    "        if field in success_df.columns:\n",
    "            populated = success_df[field].notna().sum()\n",
    "            coverage_data.append({\n",
    "                \"Field\": field.replace(\"extracted_\", \"\"),\n",
    "                \"Populated\": populated,\n",
    "                \"Coverage\": f\"{populated}/{success_count}\",\n",
    "                \"Percentage\": f\"{populated/success_count:.0%}\"\n",
    "            })\n",
    "    \n",
    "    coverage_df = pd.DataFrame(coverage_data)\n",
    "    print(f\"\\nField Coverage (of successful extractions):\\n\")\n",
    "    display(coverage_df)\n",
    "    \n",
    "    avg_coverage = sum(row[\"Populated\"] for _, row in coverage_df.iterrows()) / (len(coverage_df) * success_count) * 100\n",
    "    print(f\"\\n\u2713 Average field coverage: {avg_coverage:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q5",
   "metadata": {},
   "source": [
    "### Question 5: Estimate costs\n\nCalculate token usage and project costs for scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================",
      "QUESTION 5: Cost Estimation",
      "============================================================",
      "",
      "Calculating costs for 5 products...",
      "",
      "Cost Estimation:",
      "",
      "                            Metric    Value",
      "0  Total input tokens (5 products)   14,674",
      "1       Average tokens per product    2,935",
      "2      Estimated cost (5 products)  $0.0517",
      "3    Projected cost (450 products)    $4.65",
      "",
      "\u2713 Projected cost for full pipeline: $4.65",
      ""
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 5: Cost Estimation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def estimate_extraction_cost(text: str, model: str = \"gpt-4o\", output_tokens: int = 300) -> dict:\n",
    "    encoder = tiktoken.encoding_for_model(model)\n",
    "    input_tokens = len(encoder.encode(text))\n",
    "    pricing = {\n",
    "        \"gpt-4o\": {\"input\": 2.50 / 1_000_000, \"output\": 10.00 / 1_000_000},\n",
    "        \"gpt-4o-mini\": {\"input\": 0.15 / 1_000_000, \"output\": 0.60 / 1_000_000},\n",
    "    }\n",
    "    rates = pricing.get(model, pricing[\"gpt-4o\"])\n",
    "    input_cost = input_tokens * rates[\"input\"]\n",
    "    output_cost = output_tokens * rates[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    return {\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"total_cost\": round(total_cost, 6),\n",
    "    }\n",
    "\n",
    "print(f\"\\nCalculating costs for {len(html_data)} products...\\n\")\n",
    "\n",
    "total_input_tokens = 0\n",
    "for row in html_data:\n",
    "    if row[\"status\"] == \"fetched\":\n",
    "        cost_info = estimate_extraction_cost(row[\"cleaned_text\"])\n",
    "        total_input_tokens += cost_info[\"input_tokens\"]\n",
    "\n",
    "fetched_count = sum(1 for r in html_data if r[\"status\"] == \"fetched\")\n",
    "if fetched_count > 0:\n",
    "    avg_tokens = total_input_tokens / fetched_count\n",
    "    avg_cost = avg_tokens * (2.50 / 1_000_000) + 300 * (10.00 / 1_000_000)\n",
    "    \n",
    "    cost_summary = pd.DataFrame({\n",
    "        \"Metric\": [\n",
    "            f\"Total input tokens ({fetched_count} products)\",\n",
    "            \"Average tokens per product\",\n",
    "            f\"Estimated cost ({fetched_count} products)\",\n",
    "            \"Projected cost (450 products)\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{total_input_tokens:,}\",\n",
    "            f\"{avg_tokens:,.0f}\",\n",
    "            f\"${avg_cost * fetched_count:.4f}\",\n",
    "            f\"${avg_cost * 450:.2f}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"Cost Estimation:\\n\")\n",
    "    display(cost_summary)\n",
    "    print(f\"\\n\u2713 Projected cost for full pipeline: ${avg_cost * 450:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q6",
   "metadata": {},
   "source": [
    "### Question 6: Compare manual vs AI extraction\n\nCompare manual CSS selector approach to AI extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "traceback": [
      "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"QUESTION 6: Manual vs AI Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Manual extraction function\n",
    "def extract_manual_simple(html: str) -> dict:\n",
    "    import re\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    title_el = soup.find(\"h1\")\n",
    "    title = title_el.get_text(\" \", strip=True) if title_el else None\n",
    "    \n",
    "    text = soup.get_text()\n",
    "    price_match = re.search(r'\\$([\\d,]+(?:\\.\\d{2})?)', text)\n",
    "    price = f\"${price_match.group(1)}\" if price_match else None\n",
    "    \n",
    "    return {\n",
    "        \"product_name\": title,\n",
    "        \"price\": price,\n",
    "        \"weight\": None,\n",
    "        \"category\": None,\n",
    "    }\n",
    "\n",
    "# Compare on first successful product\n",
    "if len(html_data) > 0 and html_data[0][\"status\"] == \"fetched\":\n",
    "    test_url = df.iloc[0][\"product_url\"]\n",
    "    print(f\"\\nComparing extractions for: {df.iloc[0]['product_name']}\\n\")\n",
    "    \n",
    "    manual_html = requests.get(test_url, timeout=10).text\n",
    "    manual_result = extract_manual_simple(manual_html)\n",
    "    \n",
    "    ai_result = results_df.iloc[0].to_dict() if len(results_df) > 0 else None\n",
    "    \n",
    "    comparison = pd.DataFrame({\n",
    "        \"Field\": [\"product_name\", \"price\", \"weight\", \"category\"],\n",
    "        \"Manual (CSS selectors)\": [\n",
    "            manual_result[\"product_name\"],\n",
    "            manual_result[\"price\"],\n",
    "            manual_result[\"weight\"],\n",
    "            manual_result[\"category\"]\n",
    "        ],\n",
    "        \"AI (GPT-4o)\": [\n",
    "            ai_result.get(\"extracted_name\") if ai_result else None,\n",
    "            ai_result.get(\"extracted_price\") if ai_result else None,\n",
    "            ai_result.get(\"extracted_weight\") if ai_result else None,\n",
    "            ai_result.get(\"extracted_category\") if ai_result else None,\n",
    "        ],\n",
    "    })\n",
    "    \n",
    "    display(comparison)\n",
    "    \n",
    "    manual_populated = sum(1 for v in manual_result.values() if v is not None)\n",
    "    ai_populated = sum(1 for k in [\"extracted_name\", \"extracted_price\", \"extracted_weight\", \"extracted_category\"] \n",
    "                      if ai_result and ai_result.get(k) is not None)\n",
    "    \n",
    "    print(f\"\\nComparison Summary:\")\n",
    "    print(f\"  Manual approach:  {manual_populated}/4 fields populated\")\n",
    "    print(f\"  AI approach:      {ai_populated}/4 fields populated\")\n",
    "    print(f\"\\nKey Observations:\")\n",
    "    print(f\"  \u2713 AI extracted {ai_populated - manual_populated} additional field(s)\")\n",
    "    print(f\"  \u2713 AI works across all sites without site-specific code\")\n",
    "    print(f\"  \u2713 Manual approach requires CSS selectors for each site\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}