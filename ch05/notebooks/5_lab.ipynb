{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2278ef2-43cf-4ae9-aeb2-4a48b303d975",
   "metadata": {},
   "source": [
    "# Chapter 5 Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f437f-6266-4661-9c5b-a28255fce936",
   "metadata": {},
   "source": [
    "1. Change part of the working code in the companion notebook to replace Tesla with another popular company (e.g., Microsoft, Disney, or NVIDIA). Run the results and note any changes in sentiment across the articles returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2eeddad-e1d7-4864-b229-c62ee814d5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully extracted 100 articles.\n",
      "INFO: Preprocessed 5 articles.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 1/5: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 2/5: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 3/5: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 4/5: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 5/5: Sentiment = Negative\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El milagro de NVIDIA: va a poder seguir vendie...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nvidia on NixOS WSL – Ollama up 24/7 on your g...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How's Apple going to get out of its China jam?</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actualité : Top produit – La carte graphique N...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPUs and tariffs — Why I recommend buying a ne...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title sentiment\n",
       "0  El milagro de NVIDIA: va a poder seguir vendie...  Positive\n",
       "1  Nvidia on NixOS WSL – Ollama up 24/7 on your g...   Neutral\n",
       "2     How's Apple going to get out of its China jam?   Neutral\n",
       "3  Actualité : Top produit – La carte graphique N...   Neutral\n",
       "4  GPUs and tariffs — Why I recommend buying a ne...  Negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os                    #A\n",
    "import openai                #B\n",
    "import requests              #C\n",
    "import pandas as pd          #D\n",
    "import logging               #E\n",
    "from datetime import datetime, timedelta  #F\n",
    "from dotenv import load_dotenv            #G\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()                #H\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')  #I\n",
    "\n",
    "# Retrieve API keys from environment\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")          #J\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")      #K\n",
    "\n",
    "# Step 1: Extract articles using NewsAPI\n",
    "today = datetime.now().date()                     #L\n",
    "yesterday = today - timedelta(days=1)             #M\n",
    "\n",
    "def extract_articles(query, from_date=yesterday, api_key=NEWS_API_KEY):       #N\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={today}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        logging.info(f\"Successfully extracted {len(articles)} articles.\")\n",
    "        return articles\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch articles. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Preprocess the articles\n",
    "def preprocess_articles(articles):                #O\n",
    "    data = []\n",
    "    for article in articles[:5]:  # Limit for testing\n",
    "        title = article.get('title', '')\n",
    "        description = article.get('description', '')\n",
    "        content = article.get('content', '')\n",
    "        full_text = f\"{title} {description} {content}\".replace('\\n', ' ').strip()\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'content': full_text\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    logging.info(f\"Preprocessed {len(df)} articles.\")\n",
    "    return df\n",
    "\n",
    "# Step 3: Perform sentiment analysis with normalized output\n",
    "def perform_sentiment_analysis(article_content):  #P\n",
    "    prompt = f\"Analyze the sentiment of the following article content and return 'Positive', 'Neutral', or 'Negative' only: {article_content}\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing sentiment analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Update the DataFrame with sentiment results\n",
    "def update_with_sentiment(df):                    #Q\n",
    "    sentiments = []\n",
    "    for index, content in enumerate(df['content']):\n",
    "        sentiment = perform_sentiment_analysis(content)\n",
    "        sentiments.append(sentiment)\n",
    "        logging.info(f\"Processed article {index + 1}/{len(df)}: Sentiment = {sentiment}\")\n",
    "    \n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n",
    "\n",
    "# Run the pipeline\n",
    "articles = extract_articles('NVIDIA')              #R\n",
    "df_articles = preprocess_articles(articles)       #S\n",
    "df_with_sentiment = update_with_sentiment(df_articles)  #T\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_with_sentiment[['title', 'sentiment']]         #U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df391a18-25a5-4d50-85b5-5d012f3f1241",
   "metadata": {},
   "source": [
    "2. Modify the prompt sent to the Chat Completions endpoint so it returns a numerical sentiment score from -1 (very negative) to 1 (very positive), instead of a categorical label. Run the pipeline and verify that the new responses are numeric and well-formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400191eb-1b73-4693-9a4f-0eceb2000ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully extracted 100 articles.\n",
      "INFO: Preprocessed 5 articles.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 1/5: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 2/5: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 3/5: Sentiment = -0.3\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 4/5: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 5/5: Sentiment = 0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El milagro de NVIDIA: va a poder seguir vendie...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nvidia on NixOS WSL – Ollama up 24/7 on your g...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How's Apple going to get out of its China jam?</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Actualité : Top produit – La carte graphique N...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPUs and tariffs — Why I recommend buying a ne...</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title sentiment\n",
       "0  El milagro de NVIDIA: va a poder seguir vendie...       0.2\n",
       "1  Nvidia on NixOS WSL – Ollama up 24/7 on your g...       0.5\n",
       "2     How's Apple going to get out of its China jam?      -0.3\n",
       "3  Actualité : Top produit – La carte graphique N...       0.5\n",
       "4  GPUs and tariffs — Why I recommend buying a ne...       0.1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os                    #A\n",
    "import openai                #B\n",
    "import requests              #C\n",
    "import pandas as pd          #D\n",
    "import logging               #E\n",
    "from datetime import datetime, timedelta  #F\n",
    "from dotenv import load_dotenv            #G\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()                #H\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')  #I\n",
    "\n",
    "# Retrieve API keys from environment\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")          #J\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")      #K\n",
    "\n",
    "# Step 1: Extract articles using NewsAPI\n",
    "today = datetime.now().date()                     #L\n",
    "yesterday = today - timedelta(days=1)             #M\n",
    "\n",
    "def extract_articles(query, from_date=yesterday, api_key=NEWS_API_KEY):       #N\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={today}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        logging.info(f\"Successfully extracted {len(articles)} articles.\")\n",
    "        return articles\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch articles. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Preprocess the articles\n",
    "def preprocess_articles(articles):                #O\n",
    "    data = []\n",
    "    for article in articles[:5]:  # Limit for testing\n",
    "        title = article.get('title', '')\n",
    "        description = article.get('description', '')\n",
    "        content = article.get('content', '')\n",
    "        full_text = f\"{title} {description} {content}\".replace('\\n', ' ').strip()\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'content': full_text\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    logging.info(f\"Preprocessed {len(df)} articles.\")\n",
    "    return df\n",
    "\n",
    "# Step 3: Perform sentiment analysis with normalized output\n",
    "def perform_sentiment_analysis(article_content):  #P\n",
    "    prompt = f\"Analyze the sentiment of the following article content and return a numerical sentiment score from -1 (very negative) to 1 (very positive). Return only the number: {article_content}\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing sentiment analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Update the DataFrame with sentiment results\n",
    "def update_with_sentiment(df):                    #Q\n",
    "    sentiments = []\n",
    "    for index, content in enumerate(df['content']):\n",
    "        sentiment = perform_sentiment_analysis(content)\n",
    "        sentiments.append(sentiment)\n",
    "        logging.info(f\"Processed article {index + 1}/{len(df)}: Sentiment = {sentiment}\")\n",
    "    \n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n",
    "\n",
    "# Run the pipeline\n",
    "articles = extract_articles('NVIDIA')              #R\n",
    "df_articles = preprocess_articles(articles)       #S\n",
    "df_with_sentiment = update_with_sentiment(df_articles)  #T\n",
    "\n",
    "# Display the final DataFrame\n",
    "df_with_sentiment[['title', 'sentiment']]         #U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65601a4c-5fb0-4f36-a1bd-355692577495",
   "metadata": {},
   "source": [
    "3. Update the article preprocessing function to process up to 50 articles instead of 5. Aggregate the results using value_counts() or any simple groupby method to summarize sentiment across all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2251791-0f1c-4971-9f85-7e2219dac5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully extracted 100 articles.\n",
      "INFO: Preprocessed 50 articles.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 1/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 2/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 3/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 4/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 5/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 6/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 7/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 8/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 9/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 10/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 11/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 12/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 13/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 14/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 15/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 16/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 17/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 18/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 19/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 20/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 21/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 22/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 23/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 24/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 25/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 26/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 27/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 28/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 29/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 30/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 31/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 32/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 33/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 34/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 35/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 36/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 37/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 38/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 39/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 40/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 41/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 42/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 43/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 44/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 45/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 46/50: Sentiment = Negative\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 47/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 48/50: Sentiment = Positive\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 49/50: Sentiment = Neutral\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 50/50: Sentiment = Neutral\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Neutral     22\n",
       "Positive    14\n",
       "Negative    14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os                    #A\n",
    "import openai                #B\n",
    "import requests              #C\n",
    "import pandas as pd          #D\n",
    "import logging               #E\n",
    "from datetime import datetime, timedelta  #F\n",
    "from dotenv import load_dotenv            #G\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()                #H\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')  #I\n",
    "\n",
    "# Retrieve API keys from environment\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")          #J\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")      #K\n",
    "\n",
    "# Step 1: Extract articles using NewsAPI\n",
    "today = datetime.now().date()                     #L\n",
    "yesterday = today - timedelta(days=1)             #M\n",
    "\n",
    "def extract_articles(query, from_date=yesterday, api_key=NEWS_API_KEY):       #N\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={today}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        logging.info(f\"Successfully extracted {len(articles)} articles.\")\n",
    "        return articles\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch articles. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Preprocess the articles\n",
    "def preprocess_articles(articles):                #O\n",
    "    data = []\n",
    "    for article in articles[:50]:  # Limit for testing\n",
    "        title = article.get('title', '')\n",
    "        description = article.get('description', '')\n",
    "        content = article.get('content', '')\n",
    "        full_text = f\"{title} {description} {content}\".replace('\\n', ' ').strip()\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'content': full_text\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    logging.info(f\"Preprocessed {len(df)} articles.\")\n",
    "    return df\n",
    "\n",
    "# Step 3: Perform sentiment analysis with normalized output\n",
    "def perform_sentiment_analysis(article_content):  #P\n",
    "    prompt = f\"Analyze the sentiment of the following article content and return 'Positive', 'Neutral', or 'Negative' only: {article_content}\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing sentiment analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Update the DataFrame with sentiment results\n",
    "def update_with_sentiment(df):                    #Q\n",
    "    sentiments = []\n",
    "    for index, content in enumerate(df['content']):\n",
    "        sentiment = perform_sentiment_analysis(content)\n",
    "        sentiments.append(sentiment)\n",
    "        logging.info(f\"Processed article {index + 1}/{len(df)}: Sentiment = {sentiment}\")\n",
    "    \n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n",
    "\n",
    "# Run the pipeline\n",
    "articles = extract_articles('NVIDIA')              #R\n",
    "df_articles = preprocess_articles(articles)       #S\n",
    "df_with_sentiment = update_with_sentiment(df_articles)  #T\n",
    "df_with_sentiment['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be70df1a-d520-4d37-ae66-752bb448c097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully extracted 100 articles.\n",
      "INFO: Preprocessed 50 articles.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 1/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 2/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 3/50: Sentiment = 0.0\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 4/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 5/50: Sentiment = -0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 6/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 7/50: Sentiment = -0.3\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 8/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 9/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 10/50: Sentiment = 0.3\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 11/50: Sentiment = 0.0\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 12/50: Sentiment = -0.4\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 13/50: Sentiment = 0.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 14/50: Sentiment = -0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 15/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 16/50: Sentiment = -0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 17/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 18/50: Sentiment = 0.1\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 19/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 20/50: Sentiment = 0.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 21/50: Sentiment = -0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 22/50: Sentiment = 0.7\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 23/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 24/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 25/50: Sentiment = -0.7\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 26/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 27/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 28/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 29/50: Sentiment = 0.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 30/50: Sentiment = -0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 31/50: Sentiment = 1\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 32/50: Sentiment = 0.3\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 33/50: Sentiment = -0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 34/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 35/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 36/50: Sentiment = 0.1\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 37/50: Sentiment = 0.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 38/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 39/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 40/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 41/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 42/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 43/50: Sentiment = 0.5\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 44/50: Sentiment = 0.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 45/50: Sentiment = 0.8\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 46/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 47/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 48/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 49/50: Sentiment = 0.2\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO: Processed article 50/50: Sentiment = 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21199999999999997"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os                    #A\n",
    "import openai                #B\n",
    "import requests              #C\n",
    "import pandas as pd          #D\n",
    "import logging               #E\n",
    "from datetime import datetime, timedelta  #F\n",
    "from dotenv import load_dotenv            #G\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()                #H\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')  #I\n",
    "\n",
    "# Retrieve API keys from environment\n",
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")          #J\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")      #K\n",
    "\n",
    "# Step 1: Extract articles using NewsAPI\n",
    "today = datetime.now().date()                     #L\n",
    "yesterday = today - timedelta(days=1)             #M\n",
    "\n",
    "def extract_articles(query, from_date=yesterday, api_key=NEWS_API_KEY):       #N\n",
    "    url = f'https://newsapi.org/v2/everything?q={query}&from={from_date}&to={today}&apiKey={api_key}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        logging.info(f\"Successfully extracted {len(articles)} articles.\")\n",
    "        return articles\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch articles. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Preprocess the articles\n",
    "def preprocess_articles(articles):                #O\n",
    "    data = []\n",
    "    for article in articles[:50]:  # Limit for testing\n",
    "        title = article.get('title', '')\n",
    "        description = article.get('description', '')\n",
    "        content = article.get('content', '')\n",
    "        full_text = f\"{title} {description} {content}\".replace('\\n', ' ').strip()\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'description': description,\n",
    "            'content': full_text\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    logging.info(f\"Preprocessed {len(df)} articles.\")\n",
    "    return df\n",
    "\n",
    "# Step 3: Perform sentiment analysis with normalized output\n",
    "def perform_sentiment_analysis(article_content):  #P\n",
    "    prompt = f\"Analyze the sentiment of the following article content and return a numerical sentiment score from -1 (very negative) to 1 (very positive). Return only the number: {article_content}\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=50,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        sentiment = response.choices[0].message.content.strip()\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error performing sentiment analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Step 4: Update the DataFrame with sentiment results\n",
    "def update_with_sentiment(df):                    #Q\n",
    "    sentiments = []\n",
    "    for index, content in enumerate(df['content']):\n",
    "        sentiment = perform_sentiment_analysis(content)\n",
    "        sentiments.append(sentiment)\n",
    "        logging.info(f\"Processed article {index + 1}/{len(df)}: Sentiment = {sentiment}\")\n",
    "    \n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n",
    "\n",
    "# Run the pipeline\n",
    "articles = extract_articles('NVIDIA')              #R\n",
    "df_articles = preprocess_articles(articles)       #S\n",
    "df_with_sentiment = update_with_sentiment(df_articles)  #T\n",
    "df_with_sentiment[\"sentiment\"] = pd.to_numeric(df_with_sentiment[\"sentiment\"], errors=\"coerce\")\n",
    "df_with_sentiment['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee62b1c-57c7-4543-a8f4-f0864caad7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
