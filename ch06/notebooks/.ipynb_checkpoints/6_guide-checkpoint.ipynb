{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcdc19c9-ddb0-470a-b83c-ac0eb0a3d4f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Chapter 6 Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24207c6c-a87c-4e73-869f-159a3aea45ae",
   "metadata": {},
   "source": [
    "## 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f5cfc5-db14-48f4-952a-8deff3e59fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " email              0\n",
      "age                1\n",
      "purchase_amount    1\n",
      "dtype: int64\n",
      "\n",
      "Negative Values:\n",
      "         email  age  purchase_amount\n",
      "1  user2@.com  NaN            -50.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with inconsistent data\n",
    "df = pd.DataFrame({\n",
    "    'email': ['user1@example.com', 'user2@.com', '555-1234', 'user4@example.com'],  #A\n",
    "    'age': [25, None, 30, 40],  #B\n",
    "    'purchase_amount': [100.5, -50.0, None, 200.0]  #C\n",
    "})\n",
    "\n",
    "# Detect missing values in each column\n",
    "missing_values = df.isnull().sum()  #D\n",
    "\n",
    "# Detect negative values in the 'purchase_amount' column\n",
    "negative_values = df[df['purchase_amount'] < 0]  #E\n",
    "\n",
    "# Output the results\n",
    "print(\"Missing Values:\\n\", missing_values)  #F\n",
    "print(\"\\nNegative Values:\\n\", negative_values)  #G\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64ab2c-baf2-4807-b2e7-5edb05455191",
   "metadata": {},
   "source": [
    "## 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1fd4d4-ca8a-4b2d-a0de-1e5feabe9054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Inconsistencies: {'email': \"In the column 'email', there are a few inconsistencies:\\n\\n1. 'user2@.com': This email is likely invalid because there is a period immediately after the '@' symbol, which is not standard for email addresses.\\n2. '555-1234': This appears to be a phone number rather than an email address, indicating a data entry error.\\n\\nThe purchase amount information is not included in the data you've provided, so I can't assess inconsistencies related to negative values without that information.\", 'age': 'The request mentions checking the column \\'age\\' for inconsistencies and also references purchase amounts, which seems unrelated to the task at hand. Therefore, I\\'ll focus on identifying inconsistencies in the \\'age\\' data provided: `[25.0, nan, 30.0, 40.0]`. Here\\'s a breakdown:\\n\\n1. **25.0**: This is a valid age value.\\n\\n2. **nan**: \\'nan\\' stands for \"Not a Number\" and indicates missing data. This is an inconsistency if we expect every entry to have a valid age value. It suggests missing data which needs to be addressed, either by obtaining the correct information or determining an appropriate way to handle the missing value (e.g., using imputation).\\n\\n3. **30.0**: This is a valid age value.\\n\\n4. **40.0**: This is a valid age value.\\n\\nThe primary inconsistency here is the presence of \\'nan\\', indicating a need to manage missing data within the dataset.', 'purchase_amount': \"The column 'purchase_amount' has a few inconsistencies based on the requirement that purchase amounts should not be negative:\\n\\n1. There is a negative value: -50.0. Since purchase amounts should be non-negative, this entry is inconsistent with the expected data.\\n\\n2. There is a 'nan' (Not a Number) value present in the list. While 'nan' is not negative, its presence might indicate missing or incomplete data, which could also be considered an inconsistency if the dataset requires every entry to have a valid numeric value.\\n\\nThe other values, 100.5 and 200.0, are consistent since they are non-negative.\"}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") \n",
    "\n",
    "# Define a function to detect inconsistencies using Open AI's Chat Completions API Endpoint\n",
    "def detect_inconsistencies(df):\n",
    "    discrepancies = {}  #A\n",
    "    \n",
    "    # Loop through each column in the DataFrame\n",
    "    for col in df.columns:  #B\n",
    "        # Create a prompt to ask Open AI's Chat Completions API Endpoint for inconsistencies in the column\n",
    "        prompt = f\"Identify any inconsistencies in the column '{col}' in this data: {df[col].tolist()}. Note that purchase amount should not be negative for any item.\"  #C\n",
    "        \n",
    "        # Send the prompt to Open AI's Chat Completions API Endpoint and store the response\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )  #D\n",
    "        \n",
    "        # Save the response for the column\n",
    "        discrepancies[col] = response.choices[0].message.content.strip() #E\n",
    "    \n",
    "    return discrepancies  #F\n",
    "\n",
    "# Create a sample DataFrame with inconsistent data\n",
    "df = pd.DataFrame({\n",
    "    'email': ['user1@example.com', 'user2@.com', '555-1234', 'user4@example.com'],  #G\n",
    "    'age': [25, None, 30, 40],  #H\n",
    "    'purchase_amount': [100.5, -50.0, None, 200.0]  #I\n",
    "})\n",
    "\n",
    "# Use the function to detect inconsistencies with AI assistance\n",
    "discrepancies = detect_inconsistencies(df)  #J\n",
    "\n",
    "# Output the detected inconsistencies\n",
    "print(\"Detected Inconsistencies:\", discrepancies)  #K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619824b0-199a-4e2a-9cd5-a254e27eae7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae440111-764d-4f0c-89e8-6d26f1283574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id preferred_store_location  purchase_amount\n",
      "0            1                       NY              200\n",
      "1            2                       CA              300\n",
      "3            3                       TX              400\n",
      "4            3                     None              400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 2, 3, 3],  #A\n",
    "    'preferred_store_location': ['NY', 'CA', 'CA', 'TX', None],  #B\n",
    "    'purchase_amount': [200, 300, 300, 400, 400],  #C\n",
    "    'optional_note': [None, None, None, None, None]  #D\n",
    "})\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()  #E\n",
    "\n",
    "# Remove columns that are primarily null (e.g., more than 50% null values)\n",
    "threshold = 0.5 * len(df)  #F\n",
    "df = df.loc[:, df.isnull().sum() <= threshold]  #G\n",
    "\n",
    "# Output the cleaned DataFrame\n",
    "print(df)  #H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a539be-c889-4695-9a54-9b95d6179b9c",
   "metadata": {},
   "source": [
    "## 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b6da4f-47b7-40f4-8493-d9badec1fb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id preferred_store_location  purchase_amount\n",
      "0            1                       NY              200\n",
      "1            2                       CA              300\n",
      "3            3                       TX              400\n",
      "4            3                     None              400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the response structure\n",
    "class CleanedData(BaseModel):\n",
    "    duplicates: List[int]\n",
    "    drop_columns: List[str]\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 2, 3, 3],\n",
    "    'preferred_store_location': ['NY', 'CA', 'CA', 'TX', None],\n",
    "    'purchase_amount': [200, 300, 300, 400, 400],\n",
    "    'optional_note': [None, None, None, None, None]\n",
    "})\n",
    "\n",
    "# Format the dataset\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Prompt\n",
    "prompt = (\n",
    "    \"You are a data cleaning assistant. Review the dataset and return the following:\\n\"\n",
    "    \"- A list of row indexes that are exact duplicates based on values.\\n\"\n",
    "    \"- A list of column names that contain more than 50% null values and should be dropped.\\n\"\n",
    "    \"Respond with only the required data for cleaning.\"\n",
    ")\n",
    "\n",
    "# Completion call with response_format\n",
    "completion = openai.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": str(records)}\n",
    "    ],\n",
    "    response_format=CleanedData\n",
    ")\n",
    "\n",
    "# Extract structured output\n",
    "cleaning_info = completion.choices[0].message.parsed\n",
    "\n",
    "# Apply cleaning\n",
    "df_cleaned = df.drop(index=cleaning_info.duplicates)\n",
    "df_cleaned = df_cleaned.drop(columns=cleaning_info.drop_columns, errors='ignore')\n",
    "\n",
    "# Show cleaned output\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bef047-eab5-476b-a1f9-d862ff0754dc",
   "metadata": {},
   "source": [
    "## 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2f70c7-0508-403c-b763-c4acf3f323b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>sku</th>\n",
       "      <th>product_description</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>product_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>ABC123</td>\n",
       "      <td>red winter jacket -</td>\n",
       "      <td>Ava</td>\n",
       "      <td>Smith</td>\n",
       "      <td>winter jacket</td>\n",
       "      <td>Ava Smith</td>\n",
       "      <td>outerwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>XYZ789</td>\n",
       "      <td>bindings - lightweig</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Nguyen</td>\n",
       "      <td>bindings</td>\n",
       "      <td>Leo Nguyen</td>\n",
       "      <td>gear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short snowboard - be</td>\n",
       "      <td>Riley</td>\n",
       "      <td>Patel</td>\n",
       "      <td>short snowboard</td>\n",
       "      <td>Riley Patel</td>\n",
       "      <td>boards</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  purchase_date     sku   product_description first_name last_name  \\\n",
       "0    2023-12-31  ABC123  red winter jacket -         Ava     Smith   \n",
       "1    2023-01-01  XYZ789  bindings - lightweig        Leo    Nguyen   \n",
       "2    2023-01-15     NaN  short snowboard - be      Riley     Patel   \n",
       "\n",
       "      product_name    full_name product_category  \n",
       "0    winter jacket    Ava Smith        outerwear  \n",
       "1         bindings   Leo Nguyen             gear  \n",
       "2  short snowboard  Riley Patel           boards  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dateutil import parser  #A\n",
    "\n",
    "# Create messy dataset from Bob's shop  #B\n",
    "df = pd.DataFrame({  #C\n",
    "    'purchase_date': ['12/31/2023', '2023-01-01', '01-15-2023'],  #D\n",
    "    'sku': ['abc123', 'XYZ789', '123ABC'],  #E\n",
    "    'product_description': ['red winter jacket - insulated and waterproof', \n",
    "                            'bindings - lightweight and durable',\n",
    "                            'short snowboard - beginner friendly'],  #F\n",
    "    'first_name': ['Ava', 'Leo', 'Riley'],  #G\n",
    "    'last_name': ['Smith', 'Nguyen', 'Patel'],  #H\n",
    "    'product_name': ['winter jacket', 'bindings', 'short snowboard']  #I\n",
    "})\n",
    "\n",
    "# Standardize purchase_date format to YYYY-MM-DD  #J\n",
    "def normalize_date(val):  #K\n",
    "    try:\n",
    "        return parser.parse(val).strftime('%Y-%m-%d')  #L\n",
    "    except Exception:\n",
    "        return None  #M\n",
    "\n",
    "df['purchase_date'] = df['purchase_date'].apply(normalize_date)  #N\n",
    "\n",
    "# Enforce SKU format (3 uppercase letters + 3 digits)  #O\n",
    "df['sku'] = df['sku'].str.upper().str.extract(r'([A-Z]{3}\\d{3})', expand=False)  #P\n",
    "\n",
    "# Truncate product_description to 20 characters  #Q\n",
    "df['product_description'] = df['product_description'].str[:20]  #R\n",
    "\n",
    "# Concatenate first and last names into full_name  #S\n",
    "df['full_name'] = df['first_name'] + ' ' + df['last_name']  #T\n",
    "\n",
    "# Map product_name to standardized categories  #U\n",
    "category_map = {\n",
    "    'winter jacket': 'outerwear',\n",
    "    'bindings': 'gear',\n",
    "    'short snowboard': 'boards'\n",
    "}\n",
    "df['product_category'] = df['product_name'].map(category_map)  #V\n",
    "\n",
    "# Print cleaned DataFrame  #W\n",
    "display(df)  #X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5f469-96e2-4fc6-bd65-1f665e6fc431",
   "metadata": {},
   "source": [
    "## 6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36aeba48-2997-4956-8ffa-0e829b66ed6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  purchase_date     sku    product_description first_name last_name  \\\n",
      "0    2023-12-31    null  red winter jacket - i        Ava     Smith   \n",
      "1    2023-01-01  XYZ789   bindings - lightweig        Leo    Nguyen   \n",
      "2    2023-01-15    null  short snowboard - beg      Riley     Patel   \n",
      "\n",
      "      product_name    full_name product_category  \n",
      "0    winter jacket    Ava Smith        outerwear  \n",
      "1         bindings   Leo Nguyen             gear  \n",
      "2  short snowboard  Riley Patel           boards  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define the structured response format  #A\n",
    "class StandardizationInstructions(BaseModel):  #B\n",
    "    normalized_dates: List[str]                #C\n",
    "    cleaned_skus: List[Optional[str]]          #D\n",
    "    truncated_descriptions: List[str]          #E\n",
    "    full_names: List[str]                      #F\n",
    "    mapped_categories: List[str]               #G\n",
    "\n",
    "# Create messy dataset from Bobâ€™s shop  #H\n",
    "df = pd.DataFrame({  #I\n",
    "    'purchase_date': ['12/31/2023', '2023-01-01', '01-15-2023'],  #J\n",
    "    'sku': ['abc123', 'XYZ789', '123ABC'],  #K\n",
    "    'product_description': [\n",
    "        'red winter jacket - insulated and waterproof', \n",
    "        'bindings - lightweight and durable',\n",
    "        'short snowboard - beginner friendly'\n",
    "    ],  #L\n",
    "    'first_name': ['Ava', 'Leo', 'Riley'],  #M\n",
    "    'last_name': ['Smith', 'Nguyen', 'Patel'],  #N\n",
    "    'product_name': ['winter jacket', 'bindings', 'short snowboard']  #O\n",
    "})\n",
    "\n",
    "# Format the dataset for the prompt  #P\n",
    "records = df.to_dict(orient=\"records\")  #Q\n",
    "\n",
    "# Compose prompt to request all cleaning instructions in one shot  #R\n",
    "prompt = (\n",
    "    \"You are a data cleaning assistant. Given a dataset, return the following lists with values that match the row order exactly:\\n\"\n",
    "    \"- A list of normalized purchase_date values in YYYY-MM-DD format.\\n\"\n",
    "    \"- A list of SKUs that match the format: 3 uppercase letters followed by 3 digits. If the SKU is invalid, return null.\\n\"\n",
    "    \"- A list of product_description values truncated to 20 characters.\\n\"\n",
    "    \"- A list of full_names by combining first_name and last_name.\\n\"\n",
    "    \"- A list of standardized product categories mapped from product_name. Use one of: outerwear, gear, boards.\\n\"\n",
    "    \"Each list must contain exactly one value per row, and values must be in the same order as the input records.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Call OpenAI API with structured response  #S\n",
    "completion = openai.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt},  #T\n",
    "        {\"role\": \"user\", \"content\": str(records)}  #U\n",
    "    ],\n",
    "    response_format=StandardizationInstructions  #V\n",
    ")\n",
    "\n",
    "# Parse structured output  #W\n",
    "cleaned = completion.choices[0].message.parsed  #X\n",
    "\n",
    "# Apply cleaned values to the original DataFrame  #Y\n",
    "df['purchase_date'] = cleaned.normalized_dates\n",
    "df['sku'] = cleaned.cleaned_skus\n",
    "df['product_description'] = cleaned.truncated_descriptions\n",
    "df['full_name'] = cleaned.full_names\n",
    "df['product_category'] = cleaned.mapped_categories\n",
    "\n",
    "# Show the cleaned DataFrame  #Z\n",
    "print(df)  #AA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c06aa-614f-4780-85fd-5f6a9c2a2c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
